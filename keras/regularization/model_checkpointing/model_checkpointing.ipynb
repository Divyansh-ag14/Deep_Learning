{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xR7hbyyfuG9N"},"source":["# Steps to solve Emergency vs Non-Emergency vehicle classification\n","\n","<ol>1. Loading the dataset</ol>\n","<ol>2. Pre-processing the data</ol>\n","<ol>3. Creating training and validation set</ol>\n","<ol>4. Defining the model architecture</ol>\n","<ol>5. Compiling the model</ol>\n","<ol>6. Training the model</ol>\n","<ol><ol>Setting up model checkpointing</ol></ol>\n","<ol>7. Evaluating model performance</ol>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xq6rlm_puG9U"},"source":["## 1. Loading the dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":5511,"status":"ok","timestamp":1587726022279,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"XPYT-SDjuG9a","outputId":"6c0af488-21da-45af-c5c0-9ae656e4cdf3","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","Bad key text.latex.preview in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","\n","Bad key mathtext.fallback_to_cm in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","\n","Bad key savefig.jpeg_quality in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","\n","Bad key keymap.all_axes in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","\n","Bad key animation.avconv_path in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","\n","Bad key animation.avconv_args in file c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n","You probably need to get an updated matplotlibrc file from\n","https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n","or from the matplotlib source distribution\n","Using Theano backend.\n","WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","c:\\Users\\divyansh\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}],"source":["# import necessary libraries and functions\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# importing layers from keras\n","from keras.layers import Dense, InputLayer\n","from keras.models import Sequential\n","# importing adam optimizer from keras optimizer module \n","from keras.optimizers import Adam\n","\n","# train_test_split to create training and validation set\n","from sklearn.model_selection import train_test_split\n","# accuracy_score to calculate the accuracy of predictions\n","from sklearn.metrics import accuracy_score\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"WZdipKFauG9t"},"outputs":[],"source":["# reading the csv file\n","data = pd.read_csv('Dataset/emergency_classification.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"7pOqqh5GuG94"},"outputs":[],"source":["# defining the seed value\n","seed = 42"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"colab_type":"code","executionInfo":{"elapsed":2451,"status":"ok","timestamp":1587726115640,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"_VeBsfEAuG-B","outputId":"89082639-bb7f-4496-9dbf-b7a13c8dd092","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_names</th>\n","      <th>emergency_or_not</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.jpg</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_names  emergency_or_not\n","0       0.jpg                 1\n","1       1.jpg                 1\n","2       2.jpg                 1\n","3       3.jpg                 1\n","4       4.jpg                 1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# looking at first five rows of the data\n","data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"AMZyTsx3uG-W"},"outputs":[],"source":["# load images and store it in numpy array\n","\n","# empty list to store the images\n","X = []\n","# iterating over each image\n","for img_name in data.image_names:\n","    # loading the image using its name\n","    img = plt.imread('Dataset/images/' + img_name)\n","    # saving each image in the list\n","    X.append(img)\n","    \n","# converting the list of images into array\n","X=np.array(X)\n","\n","# storing the target variable in separate variable\n","y = data.emergency_or_not.values"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":4519,"status":"ok","timestamp":1587726146851,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"csN5M_hzuG-d","outputId":"43768ad2-366b-4f62-8100-d37a3ac82df4"},"outputs":[{"data":{"text/plain":["(2352, 224, 224, 3)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# shape of the images\n","X.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IYNJtBXLuG-x"},"source":["## 2. Pre-processing the data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1479,"status":"ok","timestamp":1587726163304,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"JsEZNNE_uG-2","outputId":"03e40b3b-d34d-4cbb-fa6f-8dfd79f1ae82","scrolled":true},"outputs":[{"data":{"text/plain":["(2352, 150528)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# converting 3 dimensional image to 1 dimensional image\n","X = X.reshape(X.shape[0], 224*224*3)\n","X.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2479,"status":"ok","timestamp":1587726176562,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"9y8rfKEguG-_","outputId":"776978fc-d3c5-4bd7-baa0-42867e951cc0"},"outputs":[{"data":{"text/plain":["(0, 255)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# minimum and maximum pixel values of images\n","X.min(), X.max()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","id":"wI3hNx3uuG_L"},"outputs":[],"source":["# normalizing the pixel values\n","X = X / X.max()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":4328,"status":"ok","timestamp":1587726187267,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"tghVTsVluG_S","outputId":"96d248ac-be40-4248-881e-e9fc5b2ee7cd"},"outputs":[{"data":{"text/plain":["(0.0, 1.0)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# minimum and maximum pixel values of images after normalizing\n","X.min(), X.max()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Scbo48PLuG_b"},"source":["## 3. Creating training and validation set"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","id":"-UmSQzb1uG_d"},"outputs":[],"source":["# creating a training and validation set\n","X_train, X_valid, y_train, y_valid=train_test_split(X,y,test_size=0.3, random_state=seed)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":3272,"status":"ok","timestamp":1587726205139,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"xTC-FgDjuG_k","outputId":"5d7f08f5-46cb-41dd-b220-cbdddacdaa23"},"outputs":[{"data":{"text/plain":["(((1646, 150528), (1646,)), ((706, 150528), (706,)))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# shape of training and validation set\n","(X_train.shape, y_train.shape), (X_valid.shape, y_valid.shape)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vskdq-4huG_r"},"source":["## 4. Defining the model architecture"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{},"colab_type":"code","id":"tLqmJg8PuHBs"},"outputs":[],"source":["# defining the model architecture\n","model=Sequential()\n","\n","model.add(InputLayer(input_shape=(224*224*3,)))\n","model.add(Dense(100, activation='sigmoid'))\n","model.add(Dense(100, activation='sigmoid'))\n","model.add(Dense(units=1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FS__sDNVrjOs"},"source":["## 5. Compiling the model"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{},"colab_type":"code","id":"BGovpAw_uHBp"},"outputs":[],"source":["# defining the adam optimizer and setting the learning rate as 10^-5\n","adam = Adam(lr=1e-5)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{},"colab_type":"code","id":"pcEUdq_Tri5x"},"outputs":[],"source":["# compiling the model\n","\n","# defining loss as binary crossentropy\n","# defining optimizer as Adam\n","# defining metrics as accuracy\n","\n","model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UJ6D8X0JtD7f"},"source":["## 6. Training the model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KMoFoDW8LHoH"},"source":["### Setting up model checkpointing"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{},"colab_type":"code","id":"bM3GB17iLMC1"},"outputs":[],"source":["# importing model checkpointing from keras callbacks\n","from keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{},"colab_type":"code","id":"2S67na5-LL_4"},"outputs":[],"source":["# defining model checkpointing\n","\n","# defining the path to store the weights\n","filepath=\"best_weights.hdf5\"\n","\n","# defining the model checkpointing and metric to monitor\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","# defining checkpointing variable\n","callbacks_list = [checkpoint]"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":88592,"status":"ok","timestamp":1587726594784,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"KL7PHbMRuHBy","outputId":"c0ef45ea-f956-451e-a9b8-b5f1da3a6ad1","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 1646 samples, validate on 706 samples\n","Epoch 1/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.6675 - accuracy: 0.5948 - val_loss: 0.6490 - val_accuracy: 0.6487\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.64873, saving model to best_weights.hdf5\n","Epoch 2/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.6355 - accuracy: 0.6616 - val_loss: 0.6374 - val_accuracy: 0.6331\n","\n","Epoch 00002: val_accuracy did not improve from 0.64873\n","Epoch 3/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.6671 - val_loss: 0.6247 - val_accuracy: 0.6558\n","\n","Epoch 00003: val_accuracy improved from 0.64873 to 0.65581, saving model to best_weights.hdf5\n","Epoch 4/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.6089 - accuracy: 0.6810 - val_loss: 0.6143 - val_accuracy: 0.6686\n","\n","Epoch 00004: val_accuracy improved from 0.65581 to 0.66856, saving model to best_weights.hdf5\n","Epoch 5/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.6036 - accuracy: 0.6920 - val_loss: 0.6028 - val_accuracy: 0.6941\n","\n","Epoch 00005: val_accuracy improved from 0.66856 to 0.69405, saving model to best_weights.hdf5\n","Epoch 6/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5912 - accuracy: 0.7072 - val_loss: 0.5965 - val_accuracy: 0.6955\n","\n","Epoch 00006: val_accuracy improved from 0.69405 to 0.69547, saving model to best_weights.hdf5\n","Epoch 7/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5849 - accuracy: 0.7139 - val_loss: 0.6031 - val_accuracy: 0.6771\n","\n","Epoch 00007: val_accuracy did not improve from 0.69547\n","Epoch 8/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5790 - accuracy: 0.7175 - val_loss: 0.6013 - val_accuracy: 0.6785\n","\n","Epoch 00008: val_accuracy did not improve from 0.69547\n","Epoch 9/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5752 - accuracy: 0.7181 - val_loss: 0.5916 - val_accuracy: 0.6898\n","\n","Epoch 00009: val_accuracy did not improve from 0.69547\n","Epoch 10/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5699 - accuracy: 0.7236 - val_loss: 0.5935 - val_accuracy: 0.6941\n","\n","Epoch 00010: val_accuracy did not improve from 0.69547\n","Epoch 11/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5641 - accuracy: 0.7278 - val_loss: 0.5967 - val_accuracy: 0.6841\n","\n","Epoch 00011: val_accuracy did not improve from 0.69547\n","Epoch 12/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.5629 - accuracy: 0.7394 - val_loss: 0.5796 - val_accuracy: 0.6941\n","\n","Epoch 00012: val_accuracy did not improve from 0.69547\n","Epoch 13/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5555 - accuracy: 0.7424 - val_loss: 0.5766 - val_accuracy: 0.7068\n","\n","Epoch 00013: val_accuracy improved from 0.69547 to 0.70680, saving model to best_weights.hdf5\n","Epoch 14/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5542 - accuracy: 0.7400 - val_loss: 0.5750 - val_accuracy: 0.7054\n","\n","Epoch 00014: val_accuracy did not improve from 0.70680\n","Epoch 15/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5516 - accuracy: 0.7461 - val_loss: 0.5733 - val_accuracy: 0.7040\n","\n","Epoch 00015: val_accuracy did not improve from 0.70680\n","Epoch 16/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5520 - accuracy: 0.7503 - val_loss: 0.5744 - val_accuracy: 0.7025\n","\n","Epoch 00016: val_accuracy did not improve from 0.70680\n","Epoch 17/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5397 - accuracy: 0.7612 - val_loss: 0.5711 - val_accuracy: 0.7040\n","\n","Epoch 00017: val_accuracy did not improve from 0.70680\n","Epoch 18/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5369 - accuracy: 0.7612 - val_loss: 0.5697 - val_accuracy: 0.7025\n","\n","Epoch 00018: val_accuracy did not improve from 0.70680\n","Epoch 19/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5333 - accuracy: 0.7643 - val_loss: 0.5685 - val_accuracy: 0.7082\n","\n","Epoch 00019: val_accuracy improved from 0.70680 to 0.70822, saving model to best_weights.hdf5\n","Epoch 20/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5298 - accuracy: 0.7655 - val_loss: 0.5726 - val_accuracy: 0.6955\n","\n","Epoch 00020: val_accuracy did not improve from 0.70822\n","Epoch 21/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5278 - accuracy: 0.7667 - val_loss: 0.5701 - val_accuracy: 0.7025\n","\n","Epoch 00021: val_accuracy did not improve from 0.70822\n","Epoch 22/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5256 - accuracy: 0.7728 - val_loss: 0.5835 - val_accuracy: 0.6884\n","\n","Epoch 00022: val_accuracy did not improve from 0.70822\n","Epoch 23/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5307 - accuracy: 0.7564 - val_loss: 0.5938 - val_accuracy: 0.6771\n","\n","Epoch 00023: val_accuracy did not improve from 0.70822\n","Epoch 24/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.5249 - accuracy: 0.7667 - val_loss: 0.5744 - val_accuracy: 0.6983\n","\n","Epoch 00024: val_accuracy did not improve from 0.70822\n","Epoch 25/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5161 - accuracy: 0.7746 - val_loss: 0.5662 - val_accuracy: 0.7068\n","\n","Epoch 00025: val_accuracy did not improve from 0.70822\n","Epoch 26/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5146 - accuracy: 0.7722 - val_loss: 0.5636 - val_accuracy: 0.7139\n","\n","Epoch 00026: val_accuracy improved from 0.70822 to 0.71388, saving model to best_weights.hdf5\n","Epoch 27/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5130 - accuracy: 0.7752 - val_loss: 0.5592 - val_accuracy: 0.7096\n","\n","Epoch 00027: val_accuracy did not improve from 0.71388\n","Epoch 28/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5075 - accuracy: 0.7764 - val_loss: 0.5584 - val_accuracy: 0.7110\n","\n","Epoch 00028: val_accuracy did not improve from 0.71388\n","Epoch 29/50\n","1646/1646 [==============================] - 7s 4ms/step - loss: 0.5079 - accuracy: 0.7843 - val_loss: 0.5586 - val_accuracy: 0.7096\n","\n","Epoch 00029: val_accuracy did not improve from 0.71388\n","Epoch 30/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.5032 - accuracy: 0.7880 - val_loss: 0.5645 - val_accuracy: 0.7082\n","\n","Epoch 00030: val_accuracy did not improve from 0.71388\n","Epoch 31/50\n","1646/1646 [==============================] - 8s 5ms/step - loss: 0.5035 - accuracy: 0.7855 - val_loss: 0.5600 - val_accuracy: 0.7068\n","\n","Epoch 00031: val_accuracy did not improve from 0.71388\n","Epoch 32/50\n","1646/1646 [==============================] - 7s 4ms/step - loss: 0.5006 - accuracy: 0.7880 - val_loss: 0.5558 - val_accuracy: 0.7125\n","\n","Epoch 00032: val_accuracy did not improve from 0.71388\n","Epoch 33/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.4967 - accuracy: 0.7934 - val_loss: 0.5558 - val_accuracy: 0.7153\n","\n","Epoch 00033: val_accuracy improved from 0.71388 to 0.71530, saving model to best_weights.hdf5\n","Epoch 34/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4916 - accuracy: 0.7922 - val_loss: 0.5618 - val_accuracy: 0.7110\n","\n","Epoch 00034: val_accuracy did not improve from 0.71530\n","Epoch 35/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4899 - accuracy: 0.8044 - val_loss: 0.5634 - val_accuracy: 0.7040\n","\n","Epoch 00035: val_accuracy did not improve from 0.71530\n","Epoch 36/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.4839 - accuracy: 0.8074 - val_loss: 0.5523 - val_accuracy: 0.7139\n","\n","Epoch 00036: val_accuracy did not improve from 0.71530\n","Epoch 37/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4833 - accuracy: 0.7977 - val_loss: 0.5531 - val_accuracy: 0.7125\n","\n","Epoch 00037: val_accuracy did not improve from 0.71530\n","Epoch 38/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4807 - accuracy: 0.8044 - val_loss: 0.5515 - val_accuracy: 0.7139\n","\n","Epoch 00038: val_accuracy did not improve from 0.71530\n","Epoch 39/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4806 - accuracy: 0.8056 - val_loss: 0.5507 - val_accuracy: 0.7139\n","\n","Epoch 00039: val_accuracy did not improve from 0.71530\n","Epoch 40/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4749 - accuracy: 0.8080 - val_loss: 0.5567 - val_accuracy: 0.7139\n","\n","Epoch 00040: val_accuracy did not improve from 0.71530\n","Epoch 41/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4738 - accuracy: 0.8074 - val_loss: 0.5720 - val_accuracy: 0.6926\n","\n","Epoch 00041: val_accuracy did not improve from 0.71530\n","Epoch 42/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4751 - accuracy: 0.8056 - val_loss: 0.5687 - val_accuracy: 0.6969\n","\n","Epoch 00042: val_accuracy did not improve from 0.71530\n","Epoch 43/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4703 - accuracy: 0.8086 - val_loss: 0.5629 - val_accuracy: 0.7054\n","\n","Epoch 00043: val_accuracy did not improve from 0.71530\n","Epoch 44/50\n","1646/1646 [==============================] - 5s 3ms/step - loss: 0.4634 - accuracy: 0.8232 - val_loss: 0.5563 - val_accuracy: 0.7054\n","\n","Epoch 00044: val_accuracy did not improve from 0.71530\n","Epoch 45/50\n","1646/1646 [==============================] - 6s 3ms/step - loss: 0.4608 - accuracy: 0.8196 - val_loss: 0.5489 - val_accuracy: 0.7139\n","\n","Epoch 00045: val_accuracy did not improve from 0.71530\n","Epoch 46/50\n","1646/1646 [==============================] - 8s 5ms/step - loss: 0.4574 - accuracy: 0.8202 - val_loss: 0.5483 - val_accuracy: 0.7210\n","\n","Epoch 00046: val_accuracy improved from 0.71530 to 0.72096, saving model to best_weights.hdf5\n","Epoch 47/50\n","1646/1646 [==============================] - 9s 5ms/step - loss: 0.4553 - accuracy: 0.8311 - val_loss: 0.5503 - val_accuracy: 0.7125\n","\n","Epoch 00047: val_accuracy did not improve from 0.72096\n","Epoch 48/50\n","1646/1646 [==============================] - 9s 5ms/step - loss: 0.4527 - accuracy: 0.8250 - val_loss: 0.5452 - val_accuracy: 0.7210\n","\n","Epoch 00048: val_accuracy did not improve from 0.72096\n","Epoch 49/50\n","1646/1646 [==============================] - 9s 5ms/step - loss: 0.4530 - accuracy: 0.8305 - val_loss: 0.5558 - val_accuracy: 0.7082\n","\n","Epoch 00049: val_accuracy did not improve from 0.72096\n","Epoch 50/50\n","1646/1646 [==============================] - 9s 5ms/step - loss: 0.4566 - accuracy: 0.8232 - val_loss: 0.5583 - val_accuracy: 0.7082\n","\n","Epoch 00050: val_accuracy did not improve from 0.72096\n"]}],"source":["# training the model for 50 epochs\n","model_history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_valid,y_valid), callbacks=callbacks_list)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4nItUUcYtYiw"},"source":["## 8. Evaluating model performance "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2743,"status":"ok","timestamp":1587726652127,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"Wbfb8_MWuHB4","outputId":"af1c5d1e-09bf-4a66-b2cc-83a7aa18e449"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on validation set: 0.7082152974504249\n"]}],"source":["# accuracy on validation set\n","print('Accuracy on validation set:', accuracy_score(y_valid, model.predict_classes(X_valid)[:, 0]))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{},"colab_type":"code","id":"qNW5PWTgO0rN"},"outputs":[],"source":["# loading the best model\n","model.load_weights(\"best_weights.hdf5\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2197,"status":"ok","timestamp":1587726687533,"user":{"displayName":"Aishwarya Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64","userId":"01105858832371513140"},"user_tz":-330},"id":"Ath-0kQ6PPzR","outputId":"eadf8bf1-9334-4d7e-8dff-9d5ea10b1511"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on validation set: 0.7209631728045326\n"]}],"source":["# accuracy on validation set\n","print('Accuracy on validation set:', accuracy_score(y_valid, model.predict_classes(X_valid)[:, 0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"e56NZ45w4o12"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Model Checkpointing in Keras.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.12 ('tensor')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"11cea9024f0d377440eaba48e9d7655bc3e56224c5f426395ac9dffd0677d0c7"}}},"nbformat":4,"nbformat_minor":0}
